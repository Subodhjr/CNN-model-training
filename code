!pip install tensorflow==2.19.0 keras==3.10.0 tensorflow-model-optimization==0.8.0 --force-reinstall

!pip install -q tensorflow-model-optimization

import tensorflow as tf
import tensorflow_model_optimization as tfmot

print(tf.__version__)
print(tfmot.__version__)

from google.colab import drive
drive.mount('/content/drive')

DATASET_PATH = "/content/drive/MyDrive/dataset"

import os
print(os.listdir(DATASET_PATH))

IMG_SIZE = 64
BATCH_SIZE = 32
NUM_CLASSES = 5
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATASET_PATH + "/train",
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    color_mode="grayscale"
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATASET_PATH + "/val",
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    color_mode="grayscale"
)

test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATASET_PATH + "/test",
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    color_mode="grayscale"
)

def normalize(image, label):
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

train_ds = train_ds.map(normalize)
val_ds = val_ds.map(normalize)
test_ds = test_ds.map(normalize)

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1),
])

def augment(image, label):
    image = data_augmentation(image)
    return image, label

train_ds = train_ds.map(augment)

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(AUTOTUNE)
val_ds   = val_ds.cache().prefetch(AUTOTUNE)
test_ds  = test_ds.cache().prefetch(AUTOTUNE)

base_model = tf.keras.Sequential([

    tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 1)),



    # --- CNN ---
    tf.keras.layers.Conv2D(16, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),

    tf.keras.layers.Conv2D(32, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),

    tf.keras.layers.Flatten(),

    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.5),

    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')
])


base_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)


base_model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=15
)


history = base_model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=18,          # total target
    initial_epoch=15,   # because you already trained 10
)

quantize_model = tfmot.quantization.keras.quantize_model

qat_model = quantize_model(base_model)

qat_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

qat_model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=5
)
qat_model.evaluate(test_ds)

def representative_dataset():
    for images, _ in train_ds.take(100):
        yield [images]

import tensorflow as tf
import os


def representative_dataset():
    for images, _ in train_ds.take(100):
        yield [images]


converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)

converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset

converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8


tflite_model = converter.convert()


tflite_path = "qat_model_int8.tflite"

with open(tflite_path, "wb") as f:
    f.write(tflite_model)

print("Model saved successfully!")
print("Size:", os.path.getsize(tflite_path)/1024, "KB")

import os
print("Size:", os.path.getsize("qat_model_int8.tflite")/1024, "KB")

from google.colab import files
files.download("qat_model_int8.tflite")

import tensorflow as tf
import numpy as np

# Load TFLite model
interpreter = tf.lite.Interpreter(model_path="qat_model_int8.tflite")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

print("Input details:", input_details)
print("Output details:", output_details)

input_scale, input_zero_point = input_details[0]['quantization']
output_scale, output_zero_point = output_details[0]['quantization']

print("Input scale:", input_scale)
print("Input zero point:", input_zero_point)

correct = 0
total = 0

for images, labels in val_ds:
    images = images.numpy()
    labels = labels.numpy()

    for i in range(len(images)):
        image = images[i]

        # Expand dims
        image = np.expand_dims(image, axis=0)

        # Convert float â†’ int8
        image = image / input_scale + input_zero_point
        image = np.clip(image, -128, 127).astype(np.int8)

        # Set input tensor
        interpreter.set_tensor(input_details[0]['index'], image)

        # Run inference
        interpreter.invoke()

        # Get output
        output = interpreter.get_tensor(output_details[0]['index'])

        # Dequantize output (optional but good practice)
        output = (output.astype(np.float32) - output_zero_point) * output_scale

        prediction = np.argmax(output)

        if prediction == labels[i]:
            correct += 1

        total += 1

print("TFLite INT8 Accuracy:", correct / total)

